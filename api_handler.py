import os
from openai import OpenAI
from dotenv import load_dotenv

# Load .env file
load_dotenv() 

# Initialize OpenAI client
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
)

def generate_response(prompt: str, model: str = "gpt-3.5-turbo") -> str:
    """
    Generates a response from OpenAI based on the provided prompt.

    Args:
        prompt (str): The text prompt to send to the OpenAI API.
        model (str): The model to use for generating the response. Default is "gpt-3.5-turbo".

    Returns:
        str: The response generated by the OpenAI model.
    """
    try:
        # Send the prompt to OpenAI and get the response
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
        )
        # Extract and return the response text
        message = response.choices[0].message.content.strip()
        return message
    except Exception as e:
        return f"An error occurred: {e}"


if __name__ == "__main__":
    user_prompt = input("Enter your prompt: ")
    response = generate_response(prompt=user_prompt)
    print(f"Response: {response}")
