import os
from openai import OpenAI
from dotenv import load_dotenv


# Load .env file
load_dotenv()

# Initialize OpenAI client
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
)

ASSISTANT_ID = os.environ.get("ASSISTANT_ID")

def generate_response(history: list, model: str = "ft:gpt-4o-2024-08-06:pa-publishing:my-experiment:B1uRZDlq") -> str:
    """
    Generates a response from OpenAI based on the provided conversation history.
    Includes a system message defining the assistant's role.

    Args:
        history (list): The conversation history, including system, user, and assistant messages.
        model (str): The model to use for generating the response. Default is "gpt-3.5-turbo".

    Returns:
        str: The response generated by OpenAI.
    """
    try:
        # Send the entire conversation history to OpenAI API
        response = client.chat.completions.create(
            model=model,
            messages=history
        )
        # Extract and return the response text
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"An error occurred: {e}"


if __name__ == "__main__":
    # Initialize conversation history with a system message if 'API_handler.py' is executed
    conversation_history = [
        {"role": "system", "content": (
            "You are an assistant for a workplace called 'Eklunda kommun'. Your purpose is to help employees "
            "find information about the organization and its staff. You have access to a PostgreSQL database that contains "
            "detailed information about employees, such as their names, roles, ages, and genders. Use this database when answering "
            "questions about specific people."
        )}
    ]

    print("Welcome to the Workplace Assistant!")
    while True:
        user_prompt = input("\nEnter your question (or 'exit' to quit): ")
        if user_prompt.lower() == "exit":
            print("Goodbye!")
            break

        # Add user's input to the conversation history
        conversation_history.append({"role": "user", "content": user_prompt})

        # Generate a response from OpenAI
        response = generate_response(history=conversation_history)

        # Add the assistant's response to the conversation history
        conversation_history.append({"role": "assistant", "content": response})

        # Print the assistant's response
        print(f"\nAssistant: {response}")
